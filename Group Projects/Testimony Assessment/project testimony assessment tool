{"cells":[{"cell_type":"markdown","metadata":{"id":"rw8XHeym-pGm"},"source":["The idea is oriented towards the creation of a tool for the analysis of testimonies of participants in court cases. On a sample of a dozen or so anonymised minutes of court hearings, it is possible to create  and  verify  a  tool  that  would  search  for  the  following  categories  of  objects  mentioned  by participants in the proceedings during the hearings:\n","1. names,\n","2. venues,\n","3. dates,\n","4. money,\n","\n","set in context, indicating the entire sentence in which the word or phrase appeared. In addition, the tool  would  allow  specific  words  or  phrases  to  be  searched  for  and  presented  in  context.  This tool seems to be a useful tool for judges, prosecutors, lawyers and solicitors. It allows them to see who  referred  to  particular  issues  in  their  depositions  and  in  what  context,  and  -  as  the  results  are presented  in  context  -  to  assess  possible  discrepancies  in  the  reporting  of  the  course  of  events.\n","This  analysis  currently  requires  a  time-consuming  search  for  the  minutes  in  the  sometimes  multi- volume case files, and further reading of each minute to look for references of interest."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HyAd463yASnE"},"outputs":[],"source":["# Download a better model for NER\n","!python -m spacy download en_core_web_trf"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rRgXFnpMDbPK"},"outputs":[],"source":["# @title ❗ Run this code cell to restart session ❗ Please ignore any error\n","#import pickle with open('data.pkl', 'wb') as f:  pickle.dump(short_text, f)  pickle.dump(full_text, f)\n","\n","import os\n","os.kill(os.getpid(), 9)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"03w-MtWp6d68"},"outputs":[],"source":["#importing necessary libraries\n","import pandas as pd\n","import spacy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H02laLGZ7GlP"},"outputs":[],"source":["df = pd.read_csv('/content/minutesENG.csv',delimiter=';')\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s2bt51e-7sm4"},"outputs":[],"source":["# problem solved by adjusting database\n","#df=df[df.columns[0:3]]\n","# df.head()"]},{"cell_type":"markdown","metadata":{"id":"OjL4XzGh_Lia"},"source":["\n","\n","A Named Entity Recognition (NER) extractor finds entities, which can be people, companies, or locations and exist within text data.\n","\n","We'll use spacy. Let's import it.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eLBHnk51A3Q3"},"outputs":[],"source":["nlp = spacy.load('en_core_web_trf')\n","\n","# We will use our short text variable\n","\n","#doc = nlp(short_text)\n","\n","# Spacy offers a nice way to display results - displacy.render()\n","\n","#spacy.displacy.render(doc, style=\"ent\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d4fLGBkHD-gs"},"outputs":[],"source":["df['PARSED'] = df['TESTIMONY'].apply(nlp)\n","df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SxQ9bs1fIJID"},"outputs":[],"source":["spacy.displacy.render(df.iloc[1][3], style=\"ent\")"]},{"cell_type":"markdown","metadata":{"id":"iEyn3SitIy6g"},"source":["GPE is in spacy countries, cities, states.\n","We have people (names), dates, and venues. Now we need objects."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n1r5-EqIJ1S7"},"outputs":[],"source":["#spacy.displacy.parse_ents(df.iloc[9][3])"]},{"cell_type":"markdown","source":["Tokenisation at this stage is complete. Next we create the search engine:\n","1. Imput user enters a word\n","2. the word is searched for in all lines. Iterate over all lines or use the vector method to return who said what immediately.\n","3. a full sentence containing that word from full stop to full stop is returned.\n","\n","The regex needs to be made three strings joined by a plus. 'First part of regex' + 'word' + 'rest of regex'.\n","\n","the icon for the word is x=input()"],"metadata":{"id":"55JoIIZeynLA"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"6FykoTDZOPtM"},"outputs":[],"source":["#word=input()\n","#print(\"first part of regex \" + word + \" the rest of regex\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Pdic0pjUTfbb"},"outputs":[],"source":["#let's import regex and write a patter for searching words\n","import re\n","\n","name=input('Name of the person testifying: ')\n","df_matches = df[['NAME','ROLE','TESTIMONY']]\n","df_matches = df_matches.query('NAME == @name')\n","\n","word=input('Keyword to search: ')\n","pattern = r'(?:^|[.!?]\\s*)([^.!?]*\\b{word}\\b[^.!?]*[.!?])'.format(word=word)\n","\n","df_matches['MATCHES'] = df_matches['TESTIMONY'].str.findall(pattern)\n","\n","matches = re.findall(pattern, df_matches.iloc[0][2])\n","\n","\n","for match in matches:\n","   print(match.strip())\n"]},{"cell_type":"code","source":["#for row in df:\n","df_matches = df[['NAME','ROLE']]\n","\n","df_matches['MATCHES'] = df['TESTIMONY'].str.findall(pattern)\n","\n","df_matches"],"metadata":{"id":"ecV-LkWTQQ8v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#import spacy\n","\n","#def highlight_word(text, word, style='cli'):\n","   nlp = spacy.load('en_core_web_sm')  # Load the English tokenizer, tagger, parser, NER, and word vectors\n","    doc = nlp(text)\n","    highlighted_text = \"\"\n","\n","     #Choose the style of highlighting based on the output environment\n","    if style == 'cli':\n","        start_tag = '\\033[94m'  # Blue color in ANSI\n","     #  end_tag = '\\033[0m'  # Reset to default\n","    elif style == 'html':\n","        start_tag = '<mark>'\n","        end_tag = '</mark>'\n","    else:\n","        start_tag = '**'  # Markdown style bold\n","        end_tag = '**'\n","\n","    # Iterate over tokens in the document\n","    for token in doc:\n","        if token.text.lower() == word.lower():\n","          #  # Add start and end tags around the word to be highlighted\n","            highlighted_text += f\"{start_tag}{token.text}{end_tag}\"\n","        else:\n","            highlighted_text += token.text\n","        highlighted_text += token.whitespace_  # Preserve the whitespace after each token\n","\n","    return highlighted_text\n","\n","# Example usage:\n","\n","let's import regex and write a patter for searching words\n","import re\n","\n","name=input('Name of the person testifying: ')\n","df_matches = df[['NAME','ROLE','TESTIMONY']]\n","df_matches = df_matches.query('NAME == @name')\n","\n","word=input('Keyword to search: ')\n","pattern = r'(?:^|[.!?]\\s*)([^.!?]*\\b{word}\\b[^.!?]*[.!?])'.format(word=word)\n","\n","#df_matches['MATCHES'] = df_matches['TESTIMONY'].str.findall(pattern)\n","\n","#matches = re.findall(pattern, df_matches.iloc[0][2])\n","\n","for match in matches:\n","    print(highlight_word(match.strip(), word, style='cli'))\n","\n","\n","#print(highlight_word(text, word, style='cli'))  # For CLI\n","#print(highlight_word(text, word, style='html'))  # Uncomment for HTML"],"metadata":{"id":"yTHyRixIdDHi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["full_text = ' '.join(df['TESTIMONY'])\n","\n","from wordcloud import WordCloud\n","from matplotlib import pyplot as plt\n","\n","cloud = WordCloud(\n","    background_color='white',\n","    width=1600,\n","    height=1000,\n","    collocations=False\n",").generate(full_text)\n","\n","plt.figure(figsize=(20,10))\n","plt.axis(\"off\")\n","plt.imshow(cloud)"],"metadata":{"id":"K0vCCeOtsCwZ"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[{"file_id":"1K7YhaNzPBggYWqcd6jyXSE-5Z8K5AGGg","timestamp":1719949739495}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}